{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ErSbMbXAf0CwcuR3z9swmD0totDa_GAA","timestamp":1710184941364}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["/content/drive/MyDrive/NLP"],"metadata":{"id":"9ajO8PRmNhQd"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import csv\n","import codecs\n","import os\n","import sys\n","import time\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/NLP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pVTioreePwff","executionInfo":{"status":"ok","timestamp":1710693234130,"user_tz":-330,"elapsed":3869,"user":{"displayName":"Shivam Kumar","userId":"14131659208237052636"}},"outputId":"37e0e687-f481-4e86-d6e0-def0c2bd0870"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/NLP\n"]}]},{"cell_type":"markdown","source":["Preprocessing Lambani Corpus (lambani.csv) and saving it to the lambani_preprocessed.csv"],"metadata":{"id":"vS8eJ5wjNIvt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgnX7t9hOcu3"},"outputs":[],"source":["import pandas as pd\n","import re\n","\n","lambani_word_pos_df = pd.read_csv('lambani.csv')\n","lambani_word_pos_df = lambani_word_pos_df.rename(columns={'Word':'word', 'POS tags': 'pos_tags'})\n","kannada_regex = re.compile(r'[\\u0C80-\\u0CFF]+')\n","regex_test = kannada_regex.findall('ಅರವಿಂದ karthik hey there ಒಲವು हिन्दी जिसके')\n","\n","pos_alias_dict = {\n","    'conjunction': ['conjunction', 'conjunctin', 'conjuntion', 'coonjuction', 'cojunction', 'conjunctio', 'conjuncton', 'c'],\n","    'noun': ['noun', 'n', 'm', 'b'],\n","    'verb': ['verb', 'vernb', 'v', 'vn'],\n","    'adjective': ['adjective', 'adjectivev', 'adjctive', 'adj', 'j', 'adje', 'sdj', 'adjectve'],\n","    'adverb': ['adverb', 'adv', 'adveb', 'adc', 'adjverb', 'adverv'],\n","    'pronoun': ['pronoun', 'pronun', 'pro', 'pn', 'ppro', 'pto', 'pronnoun', 'prro'],\n","    'preposition': ['preposition', 'pre', 'prepositon', 'ppre', 'prepostion'],\n","    'interjection': ['interjection', 'interjectin', 'inetrjection']\n","}\n","\n","pos_output_classes = ['adjective', 'adverb', 'conjunction', 'particle', 'noun', 'preposition', 'pronoun', 'verb', 'interjection']\n","pos_short = ['jj', 'rb', 'ccd', 'rpd', 'nn', 'psp', 'prp', 'vb', 'i']\n","\n","valid_lambani_sentences: list[list[str]] = []\n","valid_sentences_pos_tags: list[list[str]] = []\n","\n","current_sentence: list[str] = []\n","current_pos_tags: list[str] = []\n","is_sentence_valid = True\n","\n","for index, row in lambani_word_pos_df.iterrows():\n","    if str(row['word']) == '<START>':\n","        is_sentence_valid = True\n","        current_sentence = []\n","        current_pos_tags = []\n","    elif str(row['word']) == '<END>':\n","        if is_sentence_valid and len(current_sentence) > 0:\n","            valid_lambani_sentences.append(current_sentence)\n","            valid_sentences_pos_tags.append(current_pos_tags)\n","    else:\n","        if is_sentence_valid == False:\n","            continue\n","        else:\n","            kannada_words: list = kannada_regex.findall(str(row['word']))\n","            if len(kannada_words) == 0:\n","                is_sentence_valid = False\n","            else:\n","                found_pos_tag = False\n","                for pos in pos_alias_dict:\n","                    if str(row['pos_tags']) in pos_alias_dict[pos]:\n","                        pos_tag = pos\n","                        found_pos_tag = True\n","                        break\n","                if found_pos_tag == True:\n","                    current_sentence.append(kannada_words[0])\n","                    current_pos_tags.append(pos_tag)\n","                else:\n","                    is_sentence_valid = False\n","\n","# Save the preprocessed data into CSV without headers\n","with open('lambani_preprocessed.csv', 'w', encoding='utf-8-sig') as file:\n","    for sentence, tags in zip(valid_lambani_sentences, valid_sentences_pos_tags):\n","        file.write(' '.join(sentence) + ',' + ' '.join(tags) + '\\n')\n","\n","print(\"Preprocessed data saved to lambani_preprocessed.csv\")\n"]},{"cell_type":"markdown","source":["##Finding the unique POS tags present in the corpus"],"metadata":{"id":"1ZM9pIEC3Aq8"}},{"cell_type":"code","source":["# Read the CSV file and extract unique POS tags\n","import csv\n","csv_file = 'lambani_preprocessed.csv'\n","unique_pos_tags = set()\n","\n","with open(csv_file, 'r', encoding='utf-8') as file:\n","    next(file)  # Skip the header row\n","    for line in file:\n","        pos_tags = line.strip().split(',')[1].split()  # Assuming comma as delimiter\n","        unique_pos_tags.update(pos_tags)\n","print(\"Unique POS tags:\", unique_pos_tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d73IFRAsgZLa","executionInfo":{"status":"ok","timestamp":1710451573457,"user_tz":-330,"elapsed":667,"user":{"displayName":"Shivam Kumar","userId":"14131659208237052636"}},"outputId":"c45a1121-eb4a-4dfa-9555-d9e7b4bf2419"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique POS tags: {'adverb', 'interjection', 'noun', 'verb', 'pronoun', 'preposition', 'adjective', 'conjunction'}\n"]}]},{"cell_type":"markdown","source":["Splitting corpus into training and testing csv files"],"metadata":{"id":"D29hKtRzcYYK"}},{"cell_type":"code","source":["import pandas as pd\n","# Load the CSV file\n","data = pd.read_csv('lambani_preprocessed.csv')\n","# Select the last 100 lines for testing.csv\n","test_data = data.tail(100)\n","# Select the remaining lines for training.csv\n","train_data = data.iloc[:-100]\n","# Save the split data into separate CSV files\n","train_data.to_csv('training.csv', index=False)\n","test_data.to_csv('testing.csv', index=False)"],"metadata":{"id":"nIv_AYIdSsxT","executionInfo":{"status":"ok","timestamp":1710694066737,"user_tz":-330,"elapsed":454,"user":{"displayName":"Shivam Kumar","userId":"14131659208237052636"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"training.csv\", header=None)\n","# Function to convert POS tags to desired format\n","def convert_to_text(sentence, pos_tags):\n","    text = \"\"\n","    words = sentence.split()\n","    tags = pos_tags.split()\n","    for word, tag in zip(words, tags):\n","        text += f\"{word} {tag}\\n\"\n","    return text\n","# Writing the converted text to a file\n","with open(\"lambani_training.txt\", \"w\", encoding=\"utf-8\") as f:\n","    for _, row in df.iterrows():\n","        sentence = row[0]  # Accessing the first column\n","        pos_tags = row[1]  # Accessing the second column\n","        f.write(\"<s> START\\n\")\n","        f.write(convert_to_text(sentence, pos_tags))\n","        f.write(\"</s> END\\n\")\n"],"metadata":{"id":"SjOzdddMhQl3","executionInfo":{"status":"ok","timestamp":1710694751540,"user_tz":-330,"elapsed":1313,"user":{"displayName":"Shivam Kumar","userId":"14131659208237052636"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["NOTE: Keep lambani_testing.txt file in output folder"],"metadata":{"id":"0h9UWi-fs61A"}},{"cell_type":"markdown","source":["Output tagged text file lambani_tags.txt"],"metadata":{"id":"cO3jV_McdFDN"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP\n","!python supervised.py 0 ./data/lambani_testing.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70hSorROw5U-","executionInfo":{"status":"ok","timestamp":1710696150096,"user_tz":-330,"elapsed":33778,"user":{"displayName":"Shivam Kumar","userId":"14131659208237052636"}},"outputId":"e5695e4a-77b0-4e8d-b979-9abc557b5c62"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP\n","31.263862371444702 seconds for training\n","1.9558441638946533 seconds for testing 100 Sentences\n","\n","Kindly check ./output/lambani_tags.txt file for POS tags.\n"]}]},{"cell_type":"markdown","source":["## Calculating Accuracy"],"metadata":{"id":"6ZaQOHK1dP-w"}},{"cell_type":"markdown","source":["Firstly, preparing annotated testing file as ground truth"],"metadata":{"id":"BfK1iNmznk_E"}},{"cell_type":"code","source":["import csv\n","\n","# Function to convert CSV data to desired format\n","def convert_csv_to_txt(csv_file, output_file):\n","    with open(csv_file, 'r', encoding='utf-8') as csvfile, open(output_file, 'w', encoding='utf-8') as txtfile:\n","        reader = csv.reader(csvfile, delimiter=',')\n","        for row in reader:\n","            sentence = row[0].split()  # Split sentence into words\n","            pos_tags = row[1].split()  # Split POS tags\n","            annotated_sentence = []\n","            for word, pos in zip(sentence, pos_tags):\n","                annotated_sentence.append(f\"{word}_{pos}\")  # Combine word and POS tag\n","            txtfile.write(' '.join(annotated_sentence) + '\\n')  # Write annotated sentence to file\n","\n","# Provide input and output filenames\n","csv_input_file = 'testing.csv'\n","txt_output_file = 'annotated_testing.txt'\n","\n","# Call the function to convert CSV to txt\n","convert_csv_to_txt(csv_input_file, txt_output_file)\n"],"metadata":{"id":"_9YFAUFRiLcH","executionInfo":{"status":"ok","timestamp":1710697811913,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shivam Kumar","userId":"14131659208237052636"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Finding accuracy based on groundtruth (annotated_testing.txt) and output tagged file(lambani_tags.txt)"],"metadata":{"id":"gmCednV-if6l"}},{"cell_type":"code","source":["# Function to calculate precision\n","def precision(tp, fp):\n","    return tp / (tp + fp)\n","\n","# Function to calculate recall\n","def recall(tp, fn):\n","    return tp / (tp + fn)\n","\n","# Function to calculate F1 score\n","def f1_score(precision, recall):\n","    return 2 * (precision * recall) / (precision + recall)\n","\n","# Function to calculate accuracy\n","def accuracy(tp, tn, fp, fn):\n","    return (tp + tn) / (tp + tn + fp + fn)\n","\n","\n","# Read output file and annotated test data\n","with open(\"output/lambani_tags.txt\", \"r\", encoding=\"utf-8\") as output_file:\n","    output_lines = output_file.readlines()\n","\n","with open(\"annotated_testing.txt\", \"r\", encoding=\"utf-8\") as annotated_file:\n","    annotated_lines = annotated_file.readlines()\n","\n","# Initialize counters\n","tp = tn = fp = fn = 0\n","\n","# Iterate over lines and compare tagged words\n","for output_line, annotated_line in zip(output_lines, annotated_lines):\n","    output_tags = output_line.strip().split()[:-1]  # Ignore last character in each tag\n","    annotated_tags = annotated_line.strip().split()\n","\n","    # Check if lengths match\n","    if len(output_tags) != len(annotated_tags):\n","        print(\"Error: Lengths of lines do not match\")\n","        continue\n","\n","    # Iterate over tags and compare\n","    for output_tag, annotated_tag in zip(output_tags, annotated_tags):\n","        output_word, output_pos = output_tag.split(\"_\")\n","        annotated_word, annotated_pos = annotated_tag.split(\"_\")\n","\n","        if output_pos == annotated_pos:\n","            if output_pos == \"noun\":  # Considering only nouns for simplicity\n","                tp += 1\n","            else:\n","                tn += 1\n","        else:\n","            if output_pos == \"noun\":\n","                fp += 1\n","            else:\n","                fn += 1\n","\n","# Calculate precision, recall, F1 score, and accuracy\n","prec = precision(tp, fp)\n","rec = recall(tp, fn)\n","f1 = f1_score(prec, rec)\n","acc = accuracy(tp, tn, fp, fn)\n","\n","# Print results\n","print(\"Precision:\", prec)\n","print(\"Recall:\", rec)\n","print(\"F1 Score:\", f1)\n","print(\"Accuracy:\", acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eh57Q_ODdT_T","executionInfo":{"status":"ok","timestamp":1710698197207,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shivam Kumar","userId":"14131659208237052636"}},"outputId":"df5d67f5-26e9-4f9a-c2ef-b20fb5ed8841"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.702020202020202\n","Recall: 0.5914893617021276\n","F1 Score: 0.6420323325635104\n","Accuracy: 0.7047619047619048\n"]}]}]}